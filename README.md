![giphy](https://github.com/Malav5372/SuperMarioPPO/assets/144440737/f0db61b8-0e8e-410f-8ce3-5e59ca0e66fb)

### Introduction

Implemented with Proximal Policy Optimization (PPO), my Python source code showcases the application of AI in mastering Super Mario Bros. The focus lies on training an agent through the PPO algorithm as detailed in the [Proximal Policy Optimization Algorithms paper](https://r.search.yahoo.com/_ylt=AwrKAUdxxbxl2VEmLBu7HAx.;_ylu=Y29sbwNzZzMEcG9zAzEEdnRpZAMEc2VjA3Ny/RV=2/RE=1706898930/RO=10/RU=https%3a%2f%2farxiv.org%2fabs%2f1707.06347/RK=2/RS=wEdBCZWduN00VRaDukPtwOfWFoM-).

### Concept Overview of the algorithm :

### Some Examples : 

<p align="left">

#### world-1: 
  <img src="Example/w-1,s-1.gif" width="250">
  <img src="Example/w-1,s-2.gif" width="250">
  <img src="Example/w-1,s-3.gif" width="250">
  <img src="Example/w-1,s-4.gif" width="250"><br/>

#### world-2:
  <img src="Example/w-2,s-1.gif" width="250">
  <img src="Example/w-2,s-2.gif" width="250">
  <img src="Example/w-2,s-3.gif" width="250">
  <img src="Example/w-2,s-4.gif" width="250"><br/>
</p>


